import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors
from sklearn.compose import ColumnTransformer
from scipy import stats
import pickle
import os
import re
from difflib import get_close_matches

def create_recommendation_model(data_path='data/tracks_over_2000.csv'):
    """
    ì •ì œëœ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ì˜¤ë””ì˜¤ ë° ì¥ë¥´ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ KNN ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ í›„,
    ë‚˜ì¤‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ëª¨ë¸, ì „ì²˜ë¦¬ê¸°, ë°ì´í„°í”„ë ˆì„ì„ ì €ì¥í•©ë‹ˆë‹¤.
    """
    # ë°ì´í„° ë¡œë“œ
    try:
        df = pd.read_csv(data_path)
        # TF-IDFë¥¼ ìœ„í•´ track_genreì˜ NaN ê°’ì„ 'unknown'ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.
        if 'track_genre' in df.columns:
            df['track_genre'].fillna('unknown', inplace=True)
        print(f"íŠ¸ë™ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ")
    except FileNotFoundError:
        print(f"Error: '{data_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data_cleaning.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    # í•™ìŠµì— í™œìš©í•  íŠ¹ì„± ì •ë¦¬
    print("\ní•™ìŠµ ì „ íŠ¹ì„± ì •ë¦¬ ì¤‘...")
    skewed_features = []
    normal_features = []

    audio_features = ['energy', 'danceability', 'valence', 'acousticness',
                      'tempo', 'loudness', 'speechiness', 'instrumentalness', 'liveness']

    for feature in audio_features:
        if feature in df.columns:
            skewness = stats.skew(df[feature].dropna())
            if abs(skewness) > 1.5:
                skewed_features.append(feature)
            else:
                normal_features.append(feature)

    # íŠ¹ì„± ì„ íƒ
    numerical_features = normal_features
    robust_features = skewed_features
    if 'popularity' in df.columns and 'popularity' not in robust_features:
        robust_features.append('popularity')
    
    categorical_features = ['key', 'mode']
    text_features = 'track_genre'

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
    numerical_features = [f for f in numerical_features if f in df.columns]
    robust_features = [f for f in robust_features if f in df.columns]
    categorical_features = [f for f in categorical_features if f in df.columns]
    has_text_feature = text_features in df.columns

    print(f"\n== ì„ íƒëœ íŠ¹ì„± ==")
    print(f"  ì •ê·œ ë¶„í¬ íŠ¹ì„±: {numerical_features}")
    print(f"  ì™œë„ê°€ ë†’ì€ íŠ¹ì„±: {robust_features}")
    print(f"  ë²”ì£¼í˜• íŠ¹ì„±: {categorical_features}")
    if has_text_feature:
        print(f"  í…ìŠ¤íŠ¸ íŠ¹ì„±: {text_features}")

    # ì „ì²˜ë¦¬
    transformers = []
    if numerical_features:
        transformers.append(('normal', StandardScaler(), numerical_features))
    if robust_features:
        transformers.append(('robust', RobustScaler(), robust_features))
    if categorical_features:
        transformers.append(('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features))
    if has_text_feature:
        transformers.append(('tfidf', TfidfVectorizer(stop_words='english', max_features=300), text_features))

    preprocessor = ColumnTransformer(
        transformers=transformers,
        remainder='drop'
    )

    # ëª¨ë¸ì— ì‚¬ìš©í•  íŠ¹ì„±ë§Œ ìˆëŠ” ë°ì´í„°í”„ë ˆì„ ìƒì„±
    feature_cols = numerical_features + robust_features + categorical_features
    if has_text_feature:
        feature_cols.append(text_features)
        
    features_df = df[feature_cols]

    # ì „ì²˜ë¦¬ê¸° í•™ìŠµ ë° ë°ì´í„° ë³€í™˜
    features_transformed = preprocessor.fit_transform(features_df)
    print(f"ğŸ“ ë³€í™˜ëœ ë°ì´í„° í˜•íƒœ: {features_transformed.shape}")

    # ëª¨ë¸ í•™ìŠµ
    n_neighbors = min(20, features_transformed.shape[0] - 1)
    knn_model = NearestNeighbors(
        metric='cosine',
        algorithm='brute',
        n_neighbors=n_neighbors
    )
    knn_model.fit(features_transformed)

    # ê²°ê³¼ë¬¼ ì €ì¥
    os.makedirs('data', exist_ok=True)
    with open('data/knn_model.pkl', 'wb') as f: pickle.dump(knn_model, f)
    with open('data/preprocessor.pkl', 'wb') as f: pickle.dump(preprocessor, f)

    feature_info = {
        'numerical': numerical_features,
        'robust': robust_features,
        'categorical': categorical_features,
        'text': text_features if has_text_feature else None,
        'all': feature_cols
    }
    with open('data/feature_info.pkl', 'wb') as f: pickle.dump(feature_info, f)
    
    df.to_pickle('data/processed_tracks_df.pkl')
    print("\nì¶”ì²œ ëª¨ë¸ ìƒì„± ì™„ë£Œ")

def get_recommendations_interactive():
    """
    ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ì„ ë°›ì•„ ëŒ€í™”í˜•ìœ¼ë¡œ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    print("\n" + "="*60)
    print("Spotify ê¸°ë°˜ ë…¸ë˜ ì¶”ì²œê¸°")
    print("="*60)

    # ëª¨ë¸ íŒŒì¼ ë¡œë“œ
    try:
        with open('data/knn_model.pkl', 'rb') as f: knn_model = pickle.load(f)
        with open('data/preprocessor.pkl', 'rb') as f: preprocessor = pickle.load(f)
        with open('data/feature_info.pkl', 'rb') as f: feature_info = pickle.load(f)
        df = pd.read_pickle('data/processed_tracks_df.pkl')
        print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
    except FileNotFoundError:
        print("ëª¨ë¸ íŒŒì¼ ì—†ìŒ. ìƒˆë¡œìš´ ëª¨ë¸ì„ ìƒì„± ì¤‘...")
        create_recommendation_model()

        try:
            with open('data/knn_model.pkl', 'rb') as f: knn_model = pickle.load(f)
            with open('data/preprocessor.pkl', 'rb') as f: preprocessor = pickle.load(f)
            with open('data/feature_info.pkl', 'rb') as f: feature_info = pickle.load(f)
            df = pd.read_pickle('data/processed_tracks_df.pkl')
            print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
        except FileNotFoundError:
            print("ìƒì„± í›„ì—ë„ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ.")
            return

    while True:
        print("\n" + "-"*60)
        print("ë…¸ë˜ ì œëª© ì…ë ¥ (ì¢…ë£Œ: 'quit', 'exit', 'q')")
        print("ì˜ˆì‹œ: 'Painkiller', 'Lose Yourself'")
        print("-"*60)

        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        user_input = input("\në…¸ë˜ ì œëª©: ").strip()

        # ì¢…ë£Œ ì¡°ê±´
        if user_input.lower() in ['quit', 'exit', 'q']:
            break

        if not user_input:
            print("ë…¸ë˜ ì œëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue
        
        # 'track_name' ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°ì— ëŒ€í•œ ì˜ˆì™¸ ì²˜ë¦¬
        if 'track_name' not in df.columns:
            print("'track_name' ì»¬ëŸ¼ ì—†ìŒ.")
            break

        # ì—°ë„ íŒŒì‹±
        year_filter = None
        clean_title = user_input
        year_match = re.search(r'\b(19\d{2}|20\d{2})\b', user_input)
        if year_match:
            year_filter = int(year_match.group())
            clean_title = re.sub(r'\b(19\d{2}|20\d{2})\b', '', user_input).strip()
            print(f"ì—°ë„ í•„í„° ê°ì§€: {year_filter}")

        # ì¼ì¹˜í•˜ëŠ” ë…¸ë˜ ì°¾ê¸°
        matching_songs = df[df['track_name'].str.lower() == clean_title.lower()]
        # ì—†ìœ¼ë©´ ë¹„ìŠ·í•œ ë…¸ë˜ ì¶”ì²œ - similar
        if matching_songs.empty:
            print(f"\n'ë°ì´í„° ì—†ìŒ: {clean_title}'")
            similar = get_close_matches(clean_title, df['track_name'].unique().tolist(), n=5, cutoff=0.6)
            if similar:
                print("\nê°€ëŠ¥ì„± ìˆëŠ” ì´ë¦„ì˜ ê³¡")
                for i, title in enumerate(similar, 1):
                    print(f"  {i}. {title}")
            continue

        selected_index = None
        if len(matching_songs) > 1:
            print(f"\n'{clean_title}'ì˜ {len(matching_songs)}ê°€ì§€ ë²„ì „")
            for idx, (original_idx, row) in enumerate(matching_songs.iterrows(), 1):
                info = f"  {idx}. "
                if 'album_release_date' in row:
                    info += f"ì—°ë„: {int(row['album_release_date'])}"
                if 'popularity' in row:
                    info += f", ì¸ê¸°ë„: {row['popularity']}"
                print(info)

            if year_filter:
                year_filtered = matching_songs[matching_songs['album_release_date'] == year_filter]
                if not year_filtered.empty:
                    selected_index = year_filtered.index[0]
                    print(f"\n{year_filter}ë…„ ë²„ì „ ìë™ ì„ íƒ")
                else:
                    year_diff = abs(matching_songs['album_release_date'] - year_filter)
                    selected_index = year_diff.idxmin()
                    selected_year = matching_songs.loc[selected_index, 'album_release_date']
                    print(f"\n{year_filter}ë…„ ë²„ì „ ì—†ìŒ.")
                    print("ê°€ì¥ ê°€ê¹Œìš´ ì—°ë„ì˜ ë²„ì „ ì‚¬ìš©: {int(selected_year)}ë…„")
            else:
                print("\nìœ ì‚¬í•œ ì œëª©ì˜ ë…¸ë˜")
                print("  0. ê°€ì¥ ì¸ê¸° ìˆëŠ” ë²„ì „ ìë™ ì„ íƒ")
                print("  1-N. íŠ¹ì • ë²„ì „ ì„ íƒ")
                while True:
                    try:
                        choice = input("\nì„ íƒ (ìë™ì€ 0): ").strip()
                        if choice == "" or choice == "0":
                            if 'popularity' in matching_songs.columns:
                                selected_index = matching_songs['popularity'].idxmax()
                                print("ê°€ì¥ ì¸ê¸° ìˆëŠ” ë²„ì „")
                            else:
                                selected_index = matching_songs.index[0]
                                print("ì²« ë²ˆì§¸ ë²„ì „")
                            break
                        else:
                            choice_num = int(choice)
                            if 1 <= choice_num <= len(matching_songs):
                                selected_index = matching_songs.index[choice_num - 1]
                                print(f"{choice_num}ë²ˆ ë²„ì „")
                                break
                            else:
                                print(f"1ì—ì„œ {len(matching_songs)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    except ValueError:
                        print("ìœ íš¨í•œ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            selected_index = matching_songs.index[0]

        print("\nëª‡ ê°œì˜ ë…¸ë˜ë¥¼ ì¶”ì²œë°›ìœ¼ì‹œê² ìŠµë‹ˆê¹Œ? (ê¸°ë³¸ê°’: 10): ", end="")
        rec_input = input().strip()
        n_recommendations = 10
        if rec_input:
            try:
                n_recommendations = int(rec_input)
                n_recommendations = max(1, min(50, n_recommendations))
            except ValueError:
                print("ê¸°ë³¸ê°’ì¸ 10ê°œë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.")

        selected_song = df.loc[selected_index]
        print(f"\nì„ íƒëœ ë…¸ë˜: '{selected_song['track_name']}' (ID: {selected_song['track_id']})")
        if 'track_genre' in selected_song and selected_song['track_genre'] != 'unknown':
            print(f"   ì¥ë¥´: {selected_song['track_genre']}")
        if 'album_release_date' in selected_song:
            print(f"   ì—°ë„: {int(selected_song['album_release_date'])}")
        if 'popularity' in selected_song:
            print(f"   ì¸ê¸°ë„: {selected_song['popularity']}")

        print("\në¹„ìŠ·í•œ ë…¸ë˜ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤...")
        
        song_features = df.loc[[selected_index]][feature_info['all']]
        song_features_transformed = preprocessor.transform(song_features)

        n_candidates = min(50, len(df) - 1)
        distances, indices = knn_model.kneighbors(
            song_features_transformed,
            n_neighbors=n_candidates + 1
        )

        neighbor_indices = indices.flatten()[1:]
        neighbor_distances = distances.flatten()[1:]
        
        candidates = df.iloc[neighbor_indices].copy()
        candidates['cosine_similarity'] = 1 - neighbor_distances

        # ì…ë ¥ëœ ë…¸ë˜ì™€ ê°™ì€ ì œëª©ì˜ ëª¨ë“  ë²„ì „ì„ ì¶”ì²œ ëª©ë¡ì—ì„œ ì œì™¸
        original_title = selected_song['track_name'].lower()
        candidates = candidates[candidates['track_name'].str.lower() != original_title]

        if 'popularity' in candidates.columns:
            pop_min, pop_max = candidates['popularity'].min(), candidates['popularity'].max()
            if pop_max > pop_min:
                candidates['popularity_normalized'] = (candidates['popularity'] - pop_min) / (pop_max - pop_min)
            else:
                candidates['popularity_normalized'] = 0.5
            
            candidates['final_score'] = (0.9 * candidates['cosine_similarity']) + (0.1 * candidates['popularity_normalized'])
            candidates.sort_values('final_score', ascending=False, inplace=True)
        else:
            candidates.sort_values('cosine_similarity', ascending=False, inplace=True)

        print(f"\nìƒìœ„ {n_recommendations}ê°œ ì¶”ì²œ:")
        print("-"*60)

        for i, (_, row) in enumerate(candidates.head(n_recommendations).iterrows(), 1):
            print(f"\n{i:2}. {row['track_name']}")
            print(f"    ID: {row['track_id']}") # track_id ì¶”ê°€
            print(f"    ìœ ì‚¬ë„: {row['cosine_similarity']:.3f}")
            if 'popularity' in row:
                print(f"    ì¸ê¸°ë„: {row['popularity']}")
            if 'album_release_date' in row:
                print(f"    ì—°ë„: {int(row['album_release_date'])}")

        # ê³„ì†í• ì§€ ë¬»ê¸°
        print("\n" + "-"*60)
        continue_choice = input("ë‹¤ë¥¸ ë…¸ë˜ë¥¼ ê²€ìƒ‰í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ê±°ë‚˜, ì¢…ë£Œí•˜ë ¤ë©´ 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if continue_choice.lower() in ['quit', 'exit', 'q']:
            print("\nì¶”ì²œ ì‹œìŠ¤í…œì„ ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!")
            break

if __name__ == '__main__':
    # ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    model_files = ['knn_model.pkl', 'preprocessor.pkl', 'processed_tracks_df.pkl', 'feature_info.pkl']
    
    if not all(os.path.exists(f'data/{fname}') for fname in model_files):
        print("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ìƒˆë¡œìš´ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        create_recommendation_model()
    
    # ëŒ€í™”í˜• ì‹œìŠ¤í…œ ì‹¤í–‰
    get_recommendations_interactive()
